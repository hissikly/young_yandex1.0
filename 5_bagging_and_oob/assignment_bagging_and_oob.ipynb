{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119c9460",
   "metadata": {},
   "source": [
    "## Home assignment 05: Bagging and OOB score\n",
    "\n",
    "Пожалуйста, заполните строки кода ниже.\n",
    "Это упрощенная версия BaggedRegressor из sklearn. Обратите внимание, что API `sklearn` **не сохранился**.\n",
    "\n",
    "Ваш алгоритм должен иметь возможность обучать различные экземпляры одного и того же класса модели на загрузочных наборах данных и предоставлять [OOB score](https://en.wikipedia.org/wiki/Out-of-bag_error)  для обучающего набора.\n",
    "\n",
    "Модель следует передавать как класс модели без явных параметров и круглых скобок.\n",
    "\n",
    "Example:\n",
    "```\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "bagging_regressor.fit(LinearRegression, X, y)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ecde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06110580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedBaggingRegressor:\n",
    "\tdef __init__(self, num_bags, oob=False):\n",
    "\t\tself.num_bags = num_bags\n",
    "\t\tself.oob = oob\n",
    "\t\t\n",
    "\tdef _generate_splits(self, data: np.ndarray):\n",
    "\t\t'''\n",
    "\t\tСгенерируйте индексы для каждой сумки и сохраните их в списке self.indices_list.\n",
    "\t\t'''\n",
    "\t\tself.indices_list = []\n",
    "\t\tdata_length = len(data)\n",
    "\n",
    "\t\tself.flag_indices_in_all_bag = np.ones((data_length,))\n",
    "\t\tself.flag_indices = []\n",
    "\t\tfor bag in range(self.num_bags):\n",
    "\t\t\tbag_indices = []\n",
    "\t\t\tcur_flag = np.zeros((data_length,))\n",
    "\n",
    "\t\t\tfor _ in range(data_length):\n",
    "\t\t\t\tindex = random.randint(0, data_length - 1)\n",
    "\t\t\t\tbag_indices.append(index)\n",
    "\t\t\t\tcur_flag[index] = 1\n",
    "\t\t\t\n",
    "\t\t\tself.flag_indices.append(cur_flag.copy())\n",
    "\t\t\tself.flag_indices_in_all_bag = self.flag_indices_in_all_bag * cur_flag\n",
    "\t\t\tself.indices_list.append(bag_indices)\n",
    "\t\t\n",
    "\tdef fit(self, model_constructor, data, target):\n",
    "\t\t'''\n",
    "\t\tFit model on every bag.\n",
    "\t\tModel constructor with no parameters (and with no ()) is passed to this function.\n",
    "\t\t\n",
    "\t\texample:\n",
    "\t\t\n",
    "\t\tbagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "\t\tbagging_regressor.fit(LinearRegression, X, y)\n",
    "\t\t'''\n",
    "\t\tself.data = None\n",
    "\t\tself.target = None\n",
    "\t\tself._generate_splits(data)\n",
    "\n",
    "\t\tassert len(set(list(map(len, self.indices_list)))) == 1, 'All bags should be of the same length!'\n",
    "\t\tassert list(map(len, self.indices_list))[0] == len(data), 'All bags should contain `len(data)` number of elements!'\n",
    "\t\t\n",
    "\t\tself.models_list = []\n",
    "\t\tfor bag in range(self.num_bags):\n",
    "\t\t\tmodel = model_constructor()\n",
    "\n",
    "\t\t\tdata_bag, target_bag = data[self.indices_list[bag]], target[self.indices_list[bag]]\n",
    "\t\t\tmodel.fit(data_bag, target_bag)  # Обучаем модель\n",
    "\t\t\tself.models_list.append(model)  # Сохраняем обученную модель\n",
    "\n",
    "\t\tif self.oob:\n",
    "\t\t\tself.data = data\n",
    "\t\t\tself.target = target\n",
    "\t\t\n",
    "\tdef predict(self, data):\n",
    "\t\t'''\n",
    "\t\tGet average prediction for every object from passed dataset\n",
    "\t\t'''\n",
    "\t\tpredictions = []\n",
    "\t\tfor model in self.models_list:\n",
    "\t\t\ttmp_pred = model.predict(data)\n",
    "\t\t\tpredictions.append(tmp_pred)\n",
    "\t\t\t\n",
    "\t\treturn np.mean(predictions, axis=0)\n",
    "\n",
    "\tdef _get_oob_predictions_from_every_model(self):\n",
    "\t\t'''\t\n",
    "\t\tГенерирует список списков, где список i содержит прогнозы для объекта self.data[i]\n",
    "\t\tот всех моделей, которые не видели этот объект на этапе обучения\n",
    "\t\t'''\n",
    "\t\tlist_of_predictions_lists = [[] for _ in range(len(self.data))]\n",
    "\t\tfor bag_num in range(self.num_bags):\n",
    "\t\t\tcur_model = self.models_list[bag_num]\n",
    "\t\t\tcur_bag_indices = self.flag_indices[bag_num]\n",
    "\t\t\tfor i in range(len(self.data)):\n",
    "\t\t\t\tif cur_bag_indices[i] == 0:\n",
    "\t\t\t\t\tprediction = cur_model.predict(self.data[i].reshape((1, -1)))\n",
    "\t\t\t\t\tlist_of_predictions_lists[i].append(prediction[0])\n",
    "\t\t\n",
    "\t\tself.list_of_predictions_lists = np.array(list_of_predictions_lists, dtype=object)\n",
    "\n",
    "\t\n",
    "\tdef _get_averaged_oob_predictions(self):\n",
    "\t\t'''\n",
    "\t\tВычислите средний прогноз для каждого объекта из обучающего набора.\n",
    "\t\tЕсли объект использовался во всех сумках на этапе обучения, верните None вместо прогноза.\n",
    "\t\t'''\n",
    "\t\tself._get_oob_predictions_from_every_model()\n",
    "\t\toob_predictions = []\n",
    "\n",
    "\t\tfor i in range(len(self.list_of_predictions_lists)):\n",
    "\t\t\tif len(self.list_of_predictions_lists[i]) > 0:  # Если есть хотя бы одно предсказание\n",
    "\t\t\t\toob_predictions.append(np.mean(self.list_of_predictions_lists[i]))\n",
    "\t\t\telse:\n",
    "\t\t\t\toob_predictions.append(np.nan)  # Если объект использовался во всех сумках\n",
    "\t\t\n",
    "\t\tself.oob_predictions = np.array(oob_predictions)\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef OOB_score(self):\n",
    "\t\t'''\n",
    "\t\tВычислить среднеквадратическую ошибку для всех объектов, имеющих хотя бы один прогноз.\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\tself._get_averaged_oob_predictions()\n",
    "\t\tvalid_predictions = ~np.isnan(self.oob_predictions)\n",
    "\t\t\n",
    "\t\tif np.any(valid_predictions):\n",
    "\t\t\treturn np.mean((self.target[valid_predictions] - self.oob_predictions[valid_predictions]) ** 2)\n",
    "\t\telse:\n",
    "\t\t\treturn None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa174f",
   "metadata": {},
   "source": [
    "### Local tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaa2e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54221c2",
   "metadata": {},
   "source": [
    "#### Simple tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c94a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:52<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple tests done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    X = np.random.randn(2000, 10)\n",
    "    y = np.mean(X, axis=1)\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    assert np.mean((predictions - y)**2) < 1e-6, 'Linear dependency should be fitted with almost zero error!'\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert oob_score < 1e-6, 'OOB error for linear dependency should be also close to zero!'\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Simple tests done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4d037",
   "metadata": {},
   "source": [
    "#### Medium tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cfd3a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium tests done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(200, 150)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=20, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    average_train_error = np.mean((predictions - y)**2)\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert oob_score > average_train_error, 'OOB error must be higher than train error due to overfitting!'\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Medium tests done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725818ff",
   "metadata": {},
   "source": [
    "#### Complex tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f929d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:40<00:00, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex tests done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(2000, 15)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=100, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 1e-2, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Complex tests done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af170ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008005588285576737"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535cb6d",
   "metadata": {},
   "source": [
    "Great job! Please, save `SimplifiedBaggingRegressor` to  `bagging.py` and submit your solution to the grading system!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
